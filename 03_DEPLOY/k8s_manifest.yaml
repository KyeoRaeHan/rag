# LLM API Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-api
  namespace: llm-api
  labels:
    app: llm-api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm-api
  template:
    metadata:
      labels:
        app: llm-api
    spec:
      nodeSelector:
        nodepool-name: gpu2
        nvidia.com/mig-7g.80gb: "1"
      containers:
        - name: llm-api
          image: llm-api:latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8000
          resources:
            limits:
              nvidia.com/mig-7g.80gb: "1"

---
# LLM API Service
apiVersion: v1
kind: Service
metadata:
  name: llm-api-service
  namespace: llm-api
spec:
  type: ClusterIP
  selector:
    app: llm-api
  ports:
    - name: llm-http
      port: 8000
      targetPort: 8000
      protocol: TCP

---
# VectorDB 저장용 PVC
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: chroma-pvc
  namespace: vector-db
spec:
  accessModes:
    - ReadOnlyMany
  resources:
    requests:
      storage: 10Gi

---
# VectorDB 최초 생성 Job
apiVersion: batch/v1
kind: Job
metadata:
  name: vectordb-setting
  namespace: vector-db
spec:
  backoffLimit: 2
  ttlSecondsAfterFinished: 3600
  template:
    spec:
      nodeSelector:
          nodepool-name: gpu2
          nvidia.com/mig-7g.80gb: "1"
      restartPolicy: Never
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - llm-api
              topologyKey: "kubernetes.io/hostname"
      containers:
        - name: vectordb-setting
          image: vectordb-setting:latest
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              nvidia.com/mig-7g.80gb: "1"
          command: [ "python", "vectordb_setting.py" ]
          args:
            - "--data-path"
            - "/app/data"
            - "--persist-dir"
            - "/app/chroma_db"
            - "--batch-size"
            - "64"
            - "--persist-every"
            - "3"
            - "--preview"
            - "2"
            - "--model-name"
            - "intfloat/e5-small-v2"
          volumeMounts:
            - name: vectordb-vol
              mountPath: /app/chroma_db
              readOnly: true
          readinessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 5
            periodSeconds: 10
            failureThreshold: 3
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 10
            periodSeconds: 30
            failureThreshold: 3
      volumes:
        - name: vectordb-vol
          persistentVolumeClaim:
              claimName: chroma-pvc

---
# 검색(Retrieve)API Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vectordb-server
  namespace: vector-db
  labels:
    app: vectordb-server
spec:
  replicas: 2
  selector:
    matchLabels:
      app: vectordb-server
  template:
    metadata:
      labels:
        app: vectordb-server
    spec:
      nodeSelector:
        nodepool-name: cpu1
      containers:
        - name: server
          image: vectordb-server:latest
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8000
          volumeMounts:
            - name: vectordb-vol
              mountPath: /app/chroma_db
          readinessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 5
            periodSeconds: 10
            failureThreshold: 3
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 10
            periodSeconds: 30
            failureThreshold: 3
      volumes:
        - name: vectordb-vol
          persistentVolumeClaim:
            claimName: chroma-pvc

---
# 검색(Retrieve)API Service
apiVersion: v1
kind: Service
metadata:
  name: vectordb-server-service
  namespace: vector-db
spec:
  type: ClusterIP
  selector:
    app: vectordb-server
  ports:
    - name: vectordb-server-http
      port: 8000
      targetPort: 8000
      protocol: TCP

---
# RAG Controller Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rag-controller
  namespace: rag-controller
  labels:
    app: rag-controller
spec:
  replicas: 2
  selector:
    matchLabels:
      app: rag-controller
  template:
    metadata:
      labels:
        app: rag-controller
    spec:
      nodeSelector:
        nodepool-name: cpu1
      containers:
        - name: rag-controller
          image: rag-controller:latest
          imagePullPolicy: IfNotPresent
          envFrom:
          - configMapRef:
              name: rag-config
          ports:
            - containerPort: 8000
          readinessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 5
            periodSeconds: 10
            failureThreshold: 3
          livenessProbe:
              httpGet:
                path: /health
                port: 8000
              initialDelaySeconds: 10
              periodSeconds: 30
              failureThreshold: 3
---
# RAG Controller Service
apiVersion: v1
kind: Service
metadata:
  name: rag-controller-service
  namespace: rag-controller
spec:
  type: ClusterIP
  selector:
    app: rag-controller
  ports:
    - name: rag-http
      port: 8000
      targetPort: 8000
      protocol: TCP

---
# RAG Controller Configmap
apiVersion: v1
kind: ConfigMap
metadata:
  name: rag-config
  namespace: rag-controller
data:
  VECTORDB_ENDPOINT: "http://vectordb-server-service.vector-db.svc.cluster.local:8000/retrieve"
  LLM_ENDPOINT: "http://llm-api-service.llm-api.svc.cluster.local:8000/generate"
